{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Batch SinGAN-tf.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "FGrUB80Ecc9X"
      },
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4qXCyFP4ps7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28a2d947-9f60-420f-b43d-d012dd07443a"
      },
      "source": [
        "# Mounting Google Drive Location of training images\n",
        "drive.mount('/content/drive')\n",
        "os.chdir('/content/drive/MyDrive/FourthBrain/CapstoneSamsungOCT/')    ###### You need to edit this line"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3GzgCdyM342V"
      },
      "source": [
        "# Setting up the variables of where the processing will occur\n",
        "home_path = \"/content/drive/MyDrive/FourthBrain/CapstoneSamsungOCT/\"    ###### You need to edit this line\n",
        "sinGAN_dir = home_path + \"sinGAN-tf/\"\n",
        "data_dir = home_path + \"Data/OCT2017/\"\n",
        "synthetic_dir = data_dir + \"sinGAN-Data/synthetic/\"\n",
        "sinGAN_model = sinGAN_dir + \"main.py\"\n",
        "\n",
        "# You just need to set the class you are training for, set it to all CAPITAL\n",
        "train_class = \"CNV\"     ######  Edit this line\n",
        "sinGAN_train_dir = data_dir + \"sinGAN-Data/\" + train_class\n",
        "person_training = home_path + \"Bashar/\"    #####  Edit this line, I created the directories\n",
        "sinGAN_chkpt = person_training + \"training_checkpoints/\"\n",
        "os.chdir(person_training)\n",
        "\n",
        "#  Change this value to True only if you have new images that you want to train on, otherwise leave to FALSE\n",
        "REGEN = False"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "8-pOjfRQzAyy",
        "outputId": "41f9f734-25de-4af3-dfde-b051ee0eeb2f"
      },
      "source": [
        "sinGAN_model"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/MyDrive/FourthBrain/CapstoneSamsungOCT/sinGAN-tf/main.py'"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zDvk7LcZFho"
      },
      "source": [
        "def create_df (path, sub_dir):\n",
        "  df = pd.DataFrame(columns=['filename', 'cnv', 'dme', 'drusen', 'normal'])\n",
        "  condition = {'normal': 0, 'cnv': 0, 'dme':0, 'drusen': 0}\n",
        "  files = os.listdir(path + sub_dir)\n",
        "  if (sub_dir == 'NORMAL'):\n",
        "    condition['normal'] = 1\n",
        "  elif (sub_dir == 'CNV'):\n",
        "    condition['cnv'] = 1\n",
        "  elif (sub_dir == 'DME'):\n",
        "    condition['dme'] = 1\n",
        "  else:\n",
        "    condition['drusen']= 1\n",
        "  for f in files:\n",
        "    df = df.append({'filename': path +  sub_dir  + \"/\" + f,  \n",
        "                    'cnv': condition['cnv'],\n",
        "                    'dme': condition['dme'],\n",
        "                    'drusen': condition['drusen'],\n",
        "                    'normal': condition['normal']}, ignore_index=True)\n",
        "  return df"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQR8AUDVN_Po"
      },
      "source": [
        "classes = ['NORMAL', 'CNV', 'DME', 'DRUSEN']\n",
        "cols = [x.lower() for x in classes]\n",
        "label = {0: 'CNV', 1: 'DME', 2: 'DRUSEN', 3: 'NORMAL'}\n",
        "\n",
        "if (REGEN):\n",
        "  for directory in classes:\n",
        "    train_df = create_df(data_dir + \"sinGAN-Data/\", directory)\n",
        "    train_df.set_index('filename', inplace=True)\n",
        "    train_df.to_csv(data_dir + \"sinGAN-Data/\" + directory + \"_train.csv\")\n",
        "else:\n",
        "  # Change this line if you are going to resume training from the last file you left off\n",
        "  train_df = pd.read_csv(sinGAN_train_dir + \"_train.csv\")"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrkbnSOxc7AW"
      },
      "source": [
        "def train_sinGAN(filename):\n",
        "  !python $sinGAN_model train --image $filename --num_scales 8"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V32Zmfx2nTk_"
      },
      "source": [
        "def pick_random(filename):\n",
        "  !python $sinGAN_model inference --image $filename  --dir $sinGAN_chkpt  --mode random_sample  --inject_scale 0\n",
        "  rand_num = random.sample(range(0,49),20)\n",
        "  print (rand_num)\n",
        "  for i in rand_num:\n",
        "    os.replace(\"./results/random_sample/random_sample_\" + str(i) + \".jpg\", synthetic_dir + train_class + \"/\" + str(i) + \"_\"  + os.path.basename(filename))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OnAyD904vUCC"
      },
      "source": [
        "remainingDF = train_df.copy(True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZdrHi7h4m00",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "634907c6-6205-43c6-ce76-ee9b1cc577c3"
      },
      "source": [
        "for row in train_df[\"filename\"]:\n",
        "  train_sinGAN(\".\" + row)\n",
        "  pick_random(\".\" + row)\n",
        "  row_index = remainingDF[remainingDF['filename']==row].index\n",
        "  remainingDF.drop(row_index, inplace=True)\n",
        "  remainingDF.to_csv(train_class + \"_remaining.csv\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Directory ./training_checkpoints already exists\n",
            "2021-08-23 14:13:18.082688: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-23 14:13:18.090587: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-23 14:13:18.091252: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-23 14:13:18.092145: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX512F\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2021-08-23 14:13:18.092371: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-23 14:13:18.093009: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-23 14:13:18.093576: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-23 14:13:18.592596: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-23 14:13:18.593255: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-23 14:13:18.593903: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-23 14:13:18.594460: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2021-08-23 14:13:18.594526: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14684 MB memory:  -> device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:04.0, compute capability: 7.0\n",
            "(1, 32, 33, 3)\n",
            "(1, 43, 44, 3)\n",
            "(1, 57, 59, 3)\n",
            "(1, 76, 79, 3)\n",
            "(1, 102, 105, 3)\n",
            "(1, 136, 140, 3)\n",
            "(1, 181, 187, 3)\n",
            "(1, 242, 250, 3)\n",
            "0\n",
            "2021-08-23 14:13:19.197169: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8004\n",
            "2021-08-23 14:13:37.225957: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
            " dis_loss = -0.863\n",
            " gen_loss = 0.984\n",
            " rec_loss = 0.040\n",
            "Time taken for scale 0 is 119.97 sec\n",
            "\n",
            "1\n",
            " dis_loss = -0.355\n",
            " gen_loss = -0.335\n",
            " rec_loss = 0.002\n",
            "Time taken for scale 1 is 129.49 sec\n",
            "\n",
            "2\n",
            " dis_loss = -0.192\n",
            " gen_loss = -0.255\n",
            " rec_loss = 0.001\n",
            "Time taken for scale 2 is 145.83 sec\n",
            "\n",
            "3\n",
            " dis_loss = -0.145\n",
            " gen_loss = 0.240\n",
            " rec_loss = 0.001\n",
            "Time taken for scale 3 is 165.54 sec\n",
            "\n",
            "4\n",
            " dis_loss = 0.040\n",
            " gen_loss = -0.289\n",
            " rec_loss = 0.001\n",
            "Time taken for scale 4 is 180.68 sec\n",
            "\n",
            "5\n",
            " dis_loss = 0.031\n",
            " gen_loss = -0.066\n",
            " rec_loss = 0.001\n",
            "Time taken for scale 5 is 217.64 sec\n",
            "\n",
            "6\n",
            " dis_loss = 0.005\n",
            " gen_loss = -0.303\n",
            " rec_loss = 0.001\n",
            "Time taken for scale 6 is 319.60 sec\n",
            "\n",
            "7\n",
            " dis_loss = -0.001\n",
            " gen_loss = -0.510\n",
            " rec_loss = 0.001\n",
            "Time taken for scale 7 is 495.31 sec\n",
            "\n",
            "../Data/OCT2017/sinGAN-Data/CNV/CNV-103044-193.jpeg\n",
            "2021-08-23 14:42:56.585882: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-23 14:42:56.593804: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-23 14:42:56.594408: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-23 14:42:56.595263: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX512F\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2021-08-23 14:42:56.595498: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-23 14:42:56.596103: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-23 14:42:56.596673: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-23 14:42:57.084147: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-23 14:42:57.085176: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-23 14:42:57.086092: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-23 14:42:57.086886: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2021-08-23 14:42:57.086959: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14684 MB memory:  -> device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:04.0, compute capability: 7.0\n",
            "(1, 32, 33, 3)\n",
            "(1, 43, 44, 3)\n",
            "(1, 57, 59, 3)\n",
            "(1, 76, 79, 3)\n",
            "(1, 102, 105, 3)\n",
            "(1, 136, 140, 3)\n",
            "(1, 181, 187, 3)\n",
            "(1, 242, 250, 3)\n",
            "Directory ./results/random_sample createrd\n",
            "2021-08-23 14:42:59.658212: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
            "2021-08-23 14:43:00.302033: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8004\n",
            "[12, 6, 30, 38, 7, 43, 41, 9, 1, 20, 27, 39, 34, 22, 8, 18, 14, 17, 4, 35]\n",
            "./Data/OCT2017/sinGAN-Data/CNV/CNV-103044-193.jpeg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "At5ehoe2efsk"
      },
      "source": [
        ""
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BCuxfQTfe1pa"
      },
      "source": [
        ""
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324
        },
        "id": "MbxwmAwhfBpi",
        "outputId": "0f24dde1-33cb-4c8a-9777-078613a5c9ef"
      },
      "source": [
        "\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-4dcbd9abf9cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mremainingDF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mremainingDF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_class\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"_remaining.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4172\u001b[0m             \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4173\u001b[0m             \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4174\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4175\u001b[0m         )\n\u001b[1;32m   4176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   3887\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3888\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3889\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3891\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[0;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[1;32m   3921\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3922\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3923\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3924\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3925\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   5285\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5286\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5287\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{labels[mask]} not found in axis\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5288\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5289\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: '[0] not found in axis'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X577P41uhhoo"
      },
      "source": [
        ""
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85Wsj0gghjmu"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}