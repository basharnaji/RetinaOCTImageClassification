{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport os\n\nimage_path = '/kaggle/input/kermany2018/oct2017/OCT2017 '\noct_csv_path = '/kaggle/input/oct-csv/'\noct_singan_path = '/kaggle/input/octsingan/'\ntrain_dir = image_path + \"/train/\"\nvalid_dir = image_path + \"/val/\"\ntest_dir = image_path + \"/test/\"","metadata":{"execution":{"iopub.status.busy":"2021-09-11T16:32:03.677820Z","iopub.execute_input":"2021-09-11T16:32:03.678294Z","iopub.status.idle":"2021-09-11T16:32:03.690441Z","shell.execute_reply.started":"2021-09-11T16:32:03.678187Z","shell.execute_reply":"2021-09-11T16:32:03.689628Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"classes = ['CNV', 'DME', 'DRUSEN', 'NORMAL']\ncols = [x.upper() for x in classes]\ndirs = [train_dir, valid_dir, test_dir]\nlabel = {0: 'CNV', 1: 'DME', 2: 'DRUSEN', 3: 'NORMAL'}\nIMG_SIZE = 224\n\n# if we should read the directory structre, if False then use the CSV files already saved\n# Once you generate the csv files you should probably download them and re-upload into kaggle and set this to FALSE\nREGEN = False ","metadata":{"execution":{"iopub.status.busy":"2021-09-11T16:32:03.692311Z","iopub.execute_input":"2021-09-11T16:32:03.693082Z","iopub.status.idle":"2021-09-11T16:32:03.699717Z","shell.execute_reply.started":"2021-09-11T16:32:03.693044Z","shell.execute_reply":"2021-09-11T16:32:03.698905Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"def create_df (path, classes=classes):\n  df = pd.DataFrame(columns=['FILENAME', 'CNV', 'DME', 'DRUSEN', 'NORMAL'])\n  for sub_dir in classes:\n    condition = {'NORMAL': 0, 'CNV': 0, 'DME':0, 'DRUSEN': 0}\n    files = os.listdir(path + sub_dir)\n    if (sub_dir== 'NORMAL'):\n      condition['NORMAL'] = 1\n    elif (sub_dir == 'CNV'):\n      condition['CNV'] = 1\n    elif (sub_dir == 'DME'):\n      condition['DME'] = 1\n    else:\n      condition['DRUSEN']= 1\n    for f in files:\n      df = df.append({'FILENAME': path +  sub_dir  + \"/\" + f, \n                      'NORMAL': condition['NORMAL'], \n                      'CNV': condition['CNV'],\n                      'DME': condition['DME'],\n                      'DRUSEN': condition['DRUSEN']}, ignore_index=True)\n  return df","metadata":{"execution":{"iopub.status.busy":"2021-09-11T16:32:03.701868Z","iopub.execute_input":"2021-09-11T16:32:03.702444Z","iopub.status.idle":"2021-09-11T16:32:03.710560Z","shell.execute_reply.started":"2021-09-11T16:32:03.702399Z","shell.execute_reply":"2021-09-11T16:32:03.709354Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Generting the DataFrames of the filenames\n# this is primarily used so we can sub-sample files easier for the different training strategies\nif (REGEN):\n  train_df = create_df(train_dir)\n  valid_df = create_df(valid_dir)\n  test_df = create_df(test_dir)\n  singan_df = create_df(oct_singan_path)\n  train_df.to_csv(\"train_data.csv\")\n  valid_df.to_csv(\"valid_data.csv\")\n  test_df.to_csv(\"test_data.csv\")\n  singan_df.to_csv(\"singan_data.csv\")\nelse:\n  train_df = pd.read_csv(oct_csv_path + \"train_data.csv\")\n  valid_df = pd.read_csv(oct_csv_path + \"valid_data.csv\")\n  test_df = pd.read_csv(oct_csv_path + \"test_data.csv\")\n  singan_df = pd.read_csv(oct_csv_path + \"singan_data.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-09-11T16:32:03.712450Z","iopub.execute_input":"2021-09-11T16:32:03.712825Z","iopub.status.idle":"2021-09-11T16:32:04.032738Z","shell.execute_reply.started":"2021-09-11T16:32:03.712790Z","shell.execute_reply":"2021-09-11T16:32:04.031831Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"print (\"Training Data: \", train_df.shape)\nprint (\"Validation Data: \", valid_df.shape)\nprint (\"Test Data: \", test_df.shape)\nprint (\"SinGAN Data: \", singan_df.shape)","metadata":{"execution":{"iopub.status.busy":"2021-09-11T16:32:04.034139Z","iopub.execute_input":"2021-09-11T16:32:04.034493Z","iopub.status.idle":"2021-09-11T16:32:04.043547Z","shell.execute_reply.started":"2021-09-11T16:32:04.034458Z","shell.execute_reply":"2021-09-11T16:32:04.041861Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Training Data:  (83484, 5)\nValidation Data:  (36, 5)\nTest Data:  (972, 5)\nSinGAN Data:  (12552, 5)\n","output_type":"stream"}]},{"cell_type":"code","source":"# Printing out the # of samples for each subsample percentage \nprint (\"Trainig Data percentages:\")\nprint (\" 1% ==> \", int(.01 * train_df.shape[0]))\nprint (\" 5% ==> \", int(.05 * train_df.shape[0]))\nprint (\"10% ==> \", int(.1  * train_df.shape[0]))\nprint (\"25% ==> \", int(.25 * train_df.shape[0]))\nprint (\"50% ==> \", int(.5  * train_df.shape[0]))\nprint (\"75% ==> \", int(.75 * train_df.shape[0]))\nprint (\"90% ==> \", int(.9  * train_df.shape[0]))\nprint (\"98% ==> \", int(.98 * train_df.shape[0]))","metadata":{"execution":{"iopub.status.busy":"2021-09-11T16:32:04.044916Z","iopub.execute_input":"2021-09-11T16:32:04.045544Z","iopub.status.idle":"2021-09-11T16:32:04.057996Z","shell.execute_reply.started":"2021-09-11T16:32:04.045506Z","shell.execute_reply":"2021-09-11T16:32:04.057019Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Trainig Data percentages:\n 1% ==>  834\n 5% ==>  4174\n10% ==>  8348\n25% ==>  20871\n50% ==>  41742\n75% ==>  62613\n90% ==>  75135\n98% ==>  81814\n","output_type":"stream"}]},{"cell_type":"code","source":"singan_df.head(10)","metadata":{"execution":{"iopub.status.busy":"2021-09-11T16:32:04.059620Z","iopub.execute_input":"2021-09-11T16:32:04.060660Z","iopub.status.idle":"2021-09-11T16:32:04.084524Z","shell.execute_reply.started":"2021-09-11T16:32:04.060621Z","shell.execute_reply":"2021-09-11T16:32:04.083777Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"                                            FILENAME  CNV  DME  DRUSEN  NORMAL\n0  /kaggle/input/octsingan/CNV/47_CNV-7422289-24....    1    0       0       0\n1   /kaggle/input/octsingan/CNV/7_CNV-7585537-2.jpeg    1    0       0       0\n2  /kaggle/input/octsingan/CNV/35_CNV-6652117-496...    1    0       0       0\n3   /kaggle/input/octsingan/CNV/41_CNV-81630-49.jpeg    1    0       0       0\n4  /kaggle/input/octsingan/CNV/24_CNV-6566667-23....    1    0       0       0\n5  /kaggle/input/octsingan/CNV/23_CNV-6652117-338...    1    0       0       0\n6  /kaggle/input/octsingan/CNV/34_CNV-5603164-96....    1    0       0       0\n7  /kaggle/input/octsingan/CNV/9_CNV-7555604-53.jpeg    1    0       0       0\n8  /kaggle/input/octsingan/CNV/4_CNV-7513011-135....    1    0       0       0\n9   /kaggle/input/octsingan/CNV/16_CNV-135126-3.jpeg    1    0       0       0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>FILENAME</th>\n      <th>CNV</th>\n      <th>DME</th>\n      <th>DRUSEN</th>\n      <th>NORMAL</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>/kaggle/input/octsingan/CNV/47_CNV-7422289-24....</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>/kaggle/input/octsingan/CNV/7_CNV-7585537-2.jpeg</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>/kaggle/input/octsingan/CNV/35_CNV-6652117-496...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>/kaggle/input/octsingan/CNV/41_CNV-81630-49.jpeg</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>/kaggle/input/octsingan/CNV/24_CNV-6566667-23....</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>/kaggle/input/octsingan/CNV/23_CNV-6652117-338...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>/kaggle/input/octsingan/CNV/34_CNV-5603164-96....</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>/kaggle/input/octsingan/CNV/9_CNV-7555604-53.jpeg</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>/kaggle/input/octsingan/CNV/4_CNV-7513011-135....</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>/kaggle/input/octsingan/CNV/16_CNV-135126-3.jpeg</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Sampling 50% of the data\nsample = train_df.sample(frac=0.1, random_state=10, axis=0)\nsample = sample.append(singan_df, ignore_index=False)\nsample = sample.sample(frac=1, random_state=10, axis=0)","metadata":{"execution":{"iopub.status.busy":"2021-09-11T16:32:04.086988Z","iopub.execute_input":"2021-09-11T16:32:04.087331Z","iopub.status.idle":"2021-09-11T16:32:04.100873Z","shell.execute_reply.started":"2021-09-11T16:32:04.087298Z","shell.execute_reply":"2021-09-11T16:32:04.100160Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# determine class weights to feed into neural network during training\ndef get_classweight(df):\n  total = df.shape[0]\n  num_norm = df['NORMAL'].sum()\n  num_cnv = df['CNV'].sum()\n  num_dme = df['DME'].sum()\n  num_drusen = df['DRUSEN'].sum()\n  norm_weight = (1/num_norm) * (total/4)\n  cnv_weight = (1/num_cnv) * (total/4)\n  dme_weight = (1/num_dme) * (total/4)\n  drusen_weight = (1/num_drusen) * (total/4)\n  class_weight = {0 : cnv_weight, 1: dme_weight,\n                  2 : drusen_weight, 3: norm_weight}\n  return class_weight","metadata":{"execution":{"iopub.status.busy":"2021-09-11T16:32:04.103558Z","iopub.execute_input":"2021-09-11T16:32:04.103790Z","iopub.status.idle":"2021-09-11T16:32:04.110950Z","shell.execute_reply.started":"2021-09-11T16:32:04.103768Z","shell.execute_reply":"2021-09-11T16:32:04.110195Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"class_weight = get_classweight(sample)\nclass_weight","metadata":{"execution":{"iopub.status.busy":"2021-09-11T16:32:04.112420Z","iopub.execute_input":"2021-09-11T16:32:04.112802Z","iopub.status.idle":"2021-09-11T16:32:04.126491Z","shell.execute_reply.started":"2021-09-11T16:32:04.112752Z","shell.execute_reply":"2021-09-11T16:32:04.125624Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"{0: 0.7046527309507755,\n 1: 1.3069034517258629,\n 2: 1.2669738118331717,\n 3: 0.9742681335073653}"},"metadata":{}}]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nimport tensorflow_addons as tfa\nimport tensorflow.keras.applications as app\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator","metadata":{"execution":{"iopub.status.busy":"2021-09-11T16:32:04.129483Z","iopub.execute_input":"2021-09-11T16:32:04.129751Z","iopub.status.idle":"2021-09-11T16:32:08.795848Z","shell.execute_reply.started":"2021-09-11T16:32:04.129728Z","shell.execute_reply":"2021-09-11T16:32:08.795027Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"train_image_datagen = ImageDataGenerator(rotation_range=90, width_shift_range=[-.1,.1], height_shift_range=[-.1,.1],\n                                         shear_range=0.25, zoom_range=0.3, horizontal_flip=True,\n                                         vertical_flip=True, rescale = 1./255., validation_split=0.1)\n\n# Setting the imgages to come from the dataframe where we specify the filenames and columns to use for \"labels\"\ntrain_imgs = train_image_datagen.flow_from_dataframe(sample, directory=None, x_col='FILENAME', y_col=cols, subset=\"training\",\n                                        class_mode=\"raw\", target_size=(IMG_SIZE,IMG_SIZE), batch_size=32, seed=10)\nvalid_imgs = train_image_datagen.flow_from_dataframe(sample, directory=None, x_col='FILENAME', y_col=cols, subset=\"validation\",\n                                        class_mode=\"raw\", target_size=(IMG_SIZE,IMG_SIZE), batch_size=32, seed=10)","metadata":{"execution":{"iopub.status.busy":"2021-09-11T16:32:08.799071Z","iopub.execute_input":"2021-09-11T16:32:08.799347Z","iopub.status.idle":"2021-09-11T16:33:01.148558Z","shell.execute_reply.started":"2021-09-11T16:32:08.799322Z","shell.execute_reply":"2021-09-11T16:33:01.147156Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/keras_preprocessing/image/dataframe_iterator.py:282: UserWarning: Found 4 invalid image filename(s) in x_col=\"FILENAME\". These filename(s) will be ignored.\n  .format(n_invalid, x_col)\n","output_type":"stream"},{"name":"stdout","text":"Found 18807 validated image filenames.\nFound 2089 validated image filenames.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Creating the model based on Xception Network\ninput_layer = keras.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\nbase_model = app.xception.Xception(include_top=False, weights=\"imagenet\", input_shape=(IMG_SIZE,IMG_SIZE,3))\nbase_model.trainable = True\n\nx = base_model(input_layer)\nx = keras.layers.GlobalAveragePooling2D()(x)\noutput = keras.layers.Dense(4, activation=\"softmax\")(x)\n\nmodel = keras.Model(inputs=input_layer, outputs=output)\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-09-11T16:33:01.149877Z","iopub.execute_input":"2021-09-11T16:33:01.150226Z","iopub.status.idle":"2021-09-11T16:33:05.292690Z","shell.execute_reply.started":"2021-09-11T16:33:01.150188Z","shell.execute_reply":"2021-09-11T16:33:05.291855Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n83689472/83683744 [==============================] - 0s 0us/step\nModel: \"model\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n_________________________________________________________________\nxception (Functional)        (None, 7, 7, 2048)        20861480  \n_________________________________________________________________\nglobal_average_pooling2d (Gl (None, 2048)              0         \n_________________________________________________________________\ndense (Dense)                (None, 4)                 8196      \n=================================================================\nTotal params: 20,869,676\nTrainable params: 20,815,148\nNon-trainable params: 54,528\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"# This code did not work, it caused I/O Error 5:\n# model.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-3), loss='categorical_crossentropy', metrics='accuracy')\nmodel.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-3), loss='categorical_crossentropy', metrics=[\"accuracy\"])","metadata":{"execution":{"iopub.status.busy":"2021-09-11T16:33:05.293908Z","iopub.execute_input":"2021-09-11T16:33:05.294236Z","iopub.status.idle":"2021-09-11T16:33:05.312396Z","shell.execute_reply.started":"2021-09-11T16:33:05.294207Z","shell.execute_reply":"2021-09-11T16:33:05.311593Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# Creating a checkpoint to save the best model so that we can reload it once training is complete\ncheckpoint_cb = keras.callbacks.ModelCheckpoint(\"oct_singan.h5\", save_best_only=True)\n# Adding an an early stop callback to avoid overfitting in case the model is not improving after 5 consescutive epochs\nearlystop_cb = keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)","metadata":{"execution":{"iopub.status.busy":"2021-09-11T16:33:05.313687Z","iopub.execute_input":"2021-09-11T16:33:05.314031Z","iopub.status.idle":"2021-09-11T16:33:05.319279Z","shell.execute_reply.started":"2021-09-11T16:33:05.313996Z","shell.execute_reply":"2021-09-11T16:33:05.318343Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"history = model.fit(train_imgs,  epochs=30, verbose=1, validation_data=valid_imgs, \n                    class_weight=class_weight, callbacks=[checkpoint_cb, earlystop_cb])","metadata":{"execution":{"iopub.status.busy":"2021-09-11T16:41:20.135218Z","iopub.execute_input":"2021-09-11T16:41:20.135547Z","iopub.status.idle":"2021-09-11T18:33:53.393508Z","shell.execute_reply.started":"2021-09-11T16:41:20.135516Z","shell.execute_reply":"2021-09-11T18:33:53.392558Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Epoch 1/30\n588/588 [==============================] - 351s 596ms/step - loss: 0.5305 - accuracy: 0.8027 - val_loss: 0.6038 - val_accuracy: 0.7788\nEpoch 2/30\n588/588 [==============================] - 348s 592ms/step - loss: 0.4560 - accuracy: 0.8288 - val_loss: 0.5079 - val_accuracy: 0.8152\nEpoch 3/30\n588/588 [==============================] - 349s 594ms/step - loss: 0.4150 - accuracy: 0.8460 - val_loss: 0.6389 - val_accuracy: 0.7654\nEpoch 4/30\n588/588 [==============================] - 349s 594ms/step - loss: 0.3798 - accuracy: 0.8611 - val_loss: 0.3495 - val_accuracy: 0.8798\nEpoch 5/30\n588/588 [==============================] - 352s 598ms/step - loss: 0.3500 - accuracy: 0.8740 - val_loss: 0.3556 - val_accuracy: 0.8679\nEpoch 6/30\n588/588 [==============================] - 351s 596ms/step - loss: 0.3205 - accuracy: 0.8819 - val_loss: 0.2878 - val_accuracy: 0.8942\nEpoch 7/30\n588/588 [==============================] - 350s 595ms/step - loss: 0.3022 - accuracy: 0.8914 - val_loss: 0.3066 - val_accuracy: 0.8875\nEpoch 8/30\n588/588 [==============================] - 354s 601ms/step - loss: 0.2687 - accuracy: 0.9018 - val_loss: 0.3880 - val_accuracy: 0.8703\nEpoch 9/30\n588/588 [==============================] - 353s 600ms/step - loss: 0.2598 - accuracy: 0.9069 - val_loss: 0.2747 - val_accuracy: 0.9000\nEpoch 10/30\n588/588 [==============================] - 355s 603ms/step - loss: 0.2444 - accuracy: 0.9135 - val_loss: 0.3119 - val_accuracy: 0.8885\nEpoch 11/30\n588/588 [==============================] - 353s 600ms/step - loss: 0.2302 - accuracy: 0.9186 - val_loss: 0.4247 - val_accuracy: 0.8664\nEpoch 12/30\n588/588 [==============================] - 379s 645ms/step - loss: 0.2099 - accuracy: 0.9255 - val_loss: 0.3466 - val_accuracy: 0.8880\nEpoch 13/30\n588/588 [==============================] - 361s 613ms/step - loss: 0.1947 - accuracy: 0.9305 - val_loss: 0.2826 - val_accuracy: 0.9028\nEpoch 14/30\n588/588 [==============================] - 354s 601ms/step - loss: 0.1895 - accuracy: 0.9331 - val_loss: 0.1893 - val_accuracy: 0.9359\nEpoch 15/30\n588/588 [==============================] - 363s 617ms/step - loss: 0.1785 - accuracy: 0.9359 - val_loss: 0.2094 - val_accuracy: 0.9253\nEpoch 16/30\n588/588 [==============================] - 361s 614ms/step - loss: 0.1745 - accuracy: 0.9390 - val_loss: 0.1972 - val_accuracy: 0.9277\nEpoch 17/30\n588/588 [==============================] - 354s 602ms/step - loss: 0.1672 - accuracy: 0.9392 - val_loss: 0.2214 - val_accuracy: 0.9244\nEpoch 18/30\n588/588 [==============================] - 358s 608ms/step - loss: 0.1668 - accuracy: 0.9420 - val_loss: 0.2062 - val_accuracy: 0.9244\nEpoch 19/30\n588/588 [==============================] - 353s 599ms/step - loss: 0.1532 - accuracy: 0.9445 - val_loss: 0.2108 - val_accuracy: 0.9272\n","output_type":"stream"}]},{"cell_type":"code","source":"test_image_datagen = ImageDataGenerator( rescale = 1./255.)\n\ntest_imgs = test_image_datagen.flow_from_dataframe(test_df, directory=None, x_col='FILENAME', y_col=cols, validate_filenames=True,\n                                        class_mode=\"raw\", target_size=(224,224), batch_size=32, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2021-09-11T18:33:53.394884Z","iopub.execute_input":"2021-09-11T18:33:53.395232Z","iopub.status.idle":"2021-09-11T18:33:53.773977Z","shell.execute_reply.started":"2021-09-11T18:33:53.395195Z","shell.execute_reply":"2021-09-11T18:33:53.773046Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"Found 968 validated image filenames.\n","output_type":"stream"}]},{"cell_type":"code","source":"model.load_weights(\"oct_singan.h5\")\nmodel.evaluate(test_imgs)","metadata":{"execution":{"iopub.status.busy":"2021-09-11T18:33:53.788068Z","iopub.execute_input":"2021-09-11T18:33:53.788430Z","iopub.status.idle":"2021-09-11T18:34:03.761741Z","shell.execute_reply.started":"2021-09-11T18:33:53.788394Z","shell.execute_reply":"2021-09-11T18:34:03.760968Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"31/31 [==============================] - 9s 306ms/step - loss: 0.0328 - accuracy: 0.9886\n","output_type":"stream"},{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"[0.032822560518980026, 0.9886363744735718]"},"metadata":{}}]},{"cell_type":"code","source":"#Plotiting training results\nplt.figure(figsize=(32,12))\nplt.subplot(1,3,1)\nplt.plot(range(len(history.history[\"loss\"])), history.history['loss'], label=\"loss\")\nplt.plot(range(len(history.history[\"loss\"])), history.history['val_loss'], label=\"val_loss\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Loss\")\nplt.legend()\nplt.subplot(1,3,2)\nplt.plot(range(len(history.history[\"loss\"])), history.history[\"accuracy\"], label=\"accuracy\")\nplt.plot(range(len(history.history[\"loss\"])), history.history[\"val_accuracy\"], label=\"val_accuracy\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Accuracy\")\nplt.legend()\nplt.subplot(1,3,3)\nplt.plot(range(len(history.history[\"loss\"])), history.history['f1_score'], label=\"loss\")\nplt.plot(range(len(history.history[\"loss\"])), history.history['val_f1_score'], label=\"val_loss\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Loss\")\nplt.legend()","metadata":{"execution":{"iopub.status.busy":"2021-09-11T16:40:34.183148Z","iopub.status.idle":"2021-09-11T16:40:34.183926Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.saved_model.save(model, 'XceptionSinGANOCT')\n\n# Intialize the TFLite converter to load the SavedModel\nconverter = tf.lite.TFLiteConverter.from_saved_model('XceptionSinGANOCT')# YOUR CODE HERE\n\n# Set the optimization strategy for 'size' in the converter \nconverter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE] # YOUR CODE HERE]\n\n# Use the tool to finally convert the model\ntflite_model = converter.convert()\n\ntflite_model_file = 'XceptionSinGANOCT.tflite'\n\nwith open(tflite_model_file, \"wb\") as f:\n    f.write(tflite_model)","metadata":{"execution":{"iopub.status.busy":"2021-09-11T18:34:16.293532Z","iopub.execute_input":"2021-09-11T18:34:16.293876Z","iopub.status.idle":"2021-09-11T18:34:49.541693Z","shell.execute_reply.started":"2021-09-11T18:34:16.293845Z","shell.execute_reply":"2021-09-11T18:34:49.540752Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}