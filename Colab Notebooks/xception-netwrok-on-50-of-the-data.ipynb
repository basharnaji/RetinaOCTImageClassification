{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_path = '/kaggle/input/kermany2018/oct2017/OCT2017 '\noct_csv_path = '/kaggle/input/oct-csv/'\ntrain_dir = image_path + \"/train/\"\nvalid_dir = image_path + \"/val/\"\ntest_dir = image_path + \"/test/\"","metadata":{"execution":{"iopub.status.busy":"2021-08-12T23:02:34.301141Z","iopub.execute_input":"2021-08-12T23:02:34.301390Z","iopub.status.idle":"2021-08-12T23:02:34.307369Z","shell.execute_reply.started":"2021-08-12T23:02:34.301365Z","shell.execute_reply":"2021-08-12T23:02:34.306516Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"classes = ['CNV', 'DME', 'DRUSEN', 'NORMAL']\ncols = [x.upper() for x in classes]\ndirs = [train_dir, valid_dir, test_dir]\nlabel = {0: 'CNV', 1: 'DME', 2: 'DRUSEN', 3: 'NORMAL'}\nIMG_SIZE = 224\n\n# if we should read the directory structre, if False then use the CSV files already saved\n# Once you generate the csv files you should probably download them and re-upload into kaggle and set this to FALSE\nREGEN = False ","metadata":{"execution":{"iopub.status.busy":"2021-08-12T23:02:34.309323Z","iopub.execute_input":"2021-08-12T23:02:34.309709Z","iopub.status.idle":"2021-08-12T23:02:34.316990Z","shell.execute_reply.started":"2021-08-12T23:02:34.309671Z","shell.execute_reply":"2021-08-12T23:02:34.316230Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"def create_df (path, classes=classes):\n  df = pd.DataFrame(columns=['FILENAME', 'CNV', 'DME', 'DRUSEN', 'NORMAL'])\n  for sub_dir in classes:\n    condition = {'NORMAL': 0, 'CNV': 0, 'DME':0, 'DRUSEN': 0}\n    files = os.listdir(path + sub_dir)\n    if (sub_dir== 'NORMAL'):\n      condition['NORMAL'] = 1\n    elif (sub_dir == 'CNV'):\n      condition['CNV'] = 1\n    elif (sub_dir == 'DME'):\n      condition['DME'] = 1\n    else:\n      condition['DRUSEN']= 1\n    for f in files:\n      df = df.append({'FILENAME': path +  sub_dir  + \"/\" + f, \n                      'NORMAL': condition['NORMAL'], \n                      'CNV': condition['CNV'],\n                      'DME': condition['DME'],\n                      'DRUSEN': condition['DRUSEN']}, ignore_index=True)\n  return df","metadata":{"execution":{"iopub.status.busy":"2021-08-12T23:02:34.318601Z","iopub.execute_input":"2021-08-12T23:02:34.319037Z","iopub.status.idle":"2021-08-12T23:02:34.328531Z","shell.execute_reply.started":"2021-08-12T23:02:34.319000Z","shell.execute_reply":"2021-08-12T23:02:34.327550Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Generting the DataFrames of the filenames\n# this is primarily used so we can sub-sample files easier for the different training strategies\nif (REGEN):\n  train_df = create_df(train_dir)\n  valid_df = create_df(valid_dir)\n  test_df = create_df(test_dir)\n  train_df.to_csv(\"train_data.csv\")\n  valid_df.to_csv(\"valid_data.csv\")\n  test_df.to_csv(\"test_data.csv\")\nelse:\n  train_df = pd.read_csv(oct_csv_path + \"train_data.csv\")\n  valid_df = pd.read_csv(oct_csv_path + \"valid_data.csv\")\n  test_df = pd.read_csv(oct_csv_path + \"test_data.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-08-12T23:02:34.330109Z","iopub.execute_input":"2021-08-12T23:02:34.330524Z","iopub.status.idle":"2021-08-12T23:02:34.534433Z","shell.execute_reply.started":"2021-08-12T23:02:34.330490Z","shell.execute_reply":"2021-08-12T23:02:34.533593Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"print (\"Training Data: \", train_df.shape)\nprint (\"Validation Data: \", valid_df.shape)\nprint (\"Test Data: \", test_df.shape)","metadata":{"execution":{"iopub.status.busy":"2021-08-12T23:02:34.535753Z","iopub.execute_input":"2021-08-12T23:02:34.536108Z","iopub.status.idle":"2021-08-12T23:02:34.542200Z","shell.execute_reply.started":"2021-08-12T23:02:34.536070Z","shell.execute_reply":"2021-08-12T23:02:34.541132Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Training Data:  (83484, 5)\nValidation Data:  (36, 5)\nTest Data:  (972, 5)\n","output_type":"stream"}]},{"cell_type":"code","source":"# Printing out the # of samples for each subsample percentage \nprint (\"Trainig Data percentages:\")\nprint (\" 1% ==> \", int(.01 * train_df.shape[0]))\nprint (\" 5% ==> \", int(.05 * train_df.shape[0]))\nprint (\"10% ==> \", int(.1  * train_df.shape[0]))\nprint (\"25% ==> \", int(.25 * train_df.shape[0]))\nprint (\"50% ==> \", int(.5  * train_df.shape[0]))\nprint (\"75% ==> \", int(.75 * train_df.shape[0]))\nprint (\"90% ==> \", int(.9  * train_df.shape[0]))\nprint (\"98% ==> \", int(.98 * train_df.shape[0]))","metadata":{"execution":{"iopub.status.busy":"2021-08-12T23:02:34.543673Z","iopub.execute_input":"2021-08-12T23:02:34.544458Z","iopub.status.idle":"2021-08-12T23:02:34.556535Z","shell.execute_reply.started":"2021-08-12T23:02:34.544411Z","shell.execute_reply":"2021-08-12T23:02:34.555670Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Trainig Data percentages:\n 1% ==>  834\n 5% ==>  4174\n10% ==>  8348\n25% ==>  20871\n50% ==>  41742\n75% ==>  62613\n90% ==>  75135\n98% ==>  81814\n","output_type":"stream"}]},{"cell_type":"code","source":"# Sampling 50% of the data\nsample = train_df.sample(frac=0.5, random_state=10, axis=0)\nsample.shape","metadata":{"execution":{"iopub.status.busy":"2021-08-12T23:02:34.559585Z","iopub.execute_input":"2021-08-12T23:02:34.559866Z","iopub.status.idle":"2021-08-12T23:02:34.577427Z","shell.execute_reply.started":"2021-08-12T23:02:34.559821Z","shell.execute_reply":"2021-08-12T23:02:34.576365Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"(41742, 5)"},"metadata":{}}]},{"cell_type":"code","source":"# determine class weights to feed into neural network during training\ndef get_classweight(df):\n  total = df.shape[0]\n  num_norm = df['NORMAL'].sum()\n  num_cnv = df['CNV'].sum()\n  num_dme = df['DME'].sum()\n  num_drusen = df['DRUSEN'].sum()\n  norm_weight = (1/num_norm) * (total/4)\n  cnv_weight = (1/num_cnv) * (total/4)\n  dme_weight = (1/num_dme) * (total/4)\n  drusen_weight = (1/num_drusen) * (total/4)\n  class_weight = {0 : cnv_weight, 1: dme_weight,\n                  2 : drusen_weight, 3: norm_weight}\n  return class_weight","metadata":{"execution":{"iopub.status.busy":"2021-08-12T23:02:34.579049Z","iopub.execute_input":"2021-08-12T23:02:34.579450Z","iopub.status.idle":"2021-08-12T23:02:34.585563Z","shell.execute_reply.started":"2021-08-12T23:02:34.579417Z","shell.execute_reply":"2021-08-12T23:02:34.584643Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"class_weight = get_classweight(sample)\nclass_weight","metadata":{"execution":{"iopub.status.busy":"2021-08-12T23:02:34.586761Z","iopub.execute_input":"2021-08-12T23:02:34.587264Z","iopub.status.idle":"2021-08-12T23:02:34.601496Z","shell.execute_reply.started":"2021-08-12T23:02:34.587227Z","shell.execute_reply":"2021-08-12T23:02:34.600529Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"{0: 0.5631678359417162,\n 1: 1.842100617828773,\n 2: 2.44162377164249,\n 3: 0.7862201461613804}"},"metadata":{}}]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nimport tensorflow_addons as tfa\nimport tensorflow.keras.applications as app\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator","metadata":{"execution":{"iopub.status.busy":"2021-08-12T23:02:34.602909Z","iopub.execute_input":"2021-08-12T23:02:34.603252Z","iopub.status.idle":"2021-08-12T23:02:39.045578Z","shell.execute_reply.started":"2021-08-12T23:02:34.603216Z","shell.execute_reply":"2021-08-12T23:02:39.044669Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"train_image_datagen = ImageDataGenerator(rotation_range=90, width_shift_range=[-.1,.1], height_shift_range=[-.1,.1],\n                                         shear_range=0.25, zoom_range=0.3, horizontal_flip=True,\n                                         vertical_flip=True, rescale = 1./255., validation_split=0.1)\n\n# Setting the imgages to come from the dataframe where we specify the filenames and columns to use for \"labels\"\ntrain_imgs = train_image_datagen.flow_from_dataframe(sample, directory=None, x_col='FILENAME', y_col=cols, subset=\"training\",\n                                        class_mode=\"raw\", target_size=(IMG_SIZE,IMG_SIZE), batch_size=32, seed=10)\nvalid_imgs = train_image_datagen.flow_from_dataframe(sample, directory=None, x_col='FILENAME', y_col=cols, subset=\"validation\",\n                                        class_mode=\"raw\", target_size=(IMG_SIZE,IMG_SIZE), batch_size=32, seed=10)","metadata":{"execution":{"iopub.status.busy":"2021-08-12T23:14:47.927718Z","iopub.execute_input":"2021-08-12T23:14:47.928111Z","iopub.status.idle":"2021-08-12T23:15:00.049845Z","shell.execute_reply.started":"2021-08-12T23:14:47.928077Z","shell.execute_reply":"2021-08-12T23:15:00.047990Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"Found 37568 validated image filenames.\nFound 4174 validated image filenames.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Creating the model based on Xception Network\ninput_layer = keras.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\nbase_model = app.xception.Xception(include_top=False, weights=\"imagenet\", input_shape=(IMG_SIZE,IMG_SIZE,3))\nbase_model.trainable = False\n\nx = base_model(input_layer, training=False)\nx = keras.layers.GlobalAveragePooling2D()(x)\noutput = keras.layers.Dense(4, activation=\"softmax\")(x)\n\nmodel = keras.Model(inputs=input_layer, outputs=output)\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-08-12T23:22:12.269444Z","iopub.execute_input":"2021-08-12T23:22:12.269767Z","iopub.status.idle":"2021-08-12T23:22:13.624381Z","shell.execute_reply.started":"2021-08-12T23:22:12.269736Z","shell.execute_reply":"2021-08-12T23:22:13.623564Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"Model: \"model_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_7 (InputLayer)         [(None, 224, 224, 3)]     0         \n_________________________________________________________________\nxception (Functional)        (None, 7, 7, 2048)        20861480  \n_________________________________________________________________\nglobal_average_pooling2d_1 ( (None, 2048)              0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 4)                 8196      \n=================================================================\nTotal params: 20,869,676\nTrainable params: 8,196\nNon-trainable params: 20,861,480\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"# This code did not work, it caused I/O Error 5:\n# model.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-3), loss='categorical_crossentropy', metrics='accuracy')\nmodel.compile(optimizer=keras.optimizers.Adam(), loss='categorical_crossentropy', metrics=[tfa.metrics.F1Score(4,\"micro\")])","metadata":{"execution":{"iopub.status.busy":"2021-08-12T23:23:14.497975Z","iopub.execute_input":"2021-08-12T23:23:14.498305Z","iopub.status.idle":"2021-08-12T23:23:14.518492Z","shell.execute_reply.started":"2021-08-12T23:23:14.498272Z","shell.execute_reply":"2021-08-12T23:23:14.517613Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"# Creating a checkpoint to save the best model so that we can reload it once training is complete\ncheckpoint_cb = keras.callbacks.ModelCheckpoint(\"oct_xception50per.h5\", save_best_only=True)\n# Adding an an early stop callback to avoid overfitting in case the model is not improving after 5 consescutive epochs\nearlystop_cb = keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)","metadata":{"execution":{"iopub.status.busy":"2021-08-12T23:23:17.126617Z","iopub.execute_input":"2021-08-12T23:23:17.126962Z","iopub.status.idle":"2021-08-12T23:23:17.131655Z","shell.execute_reply.started":"2021-08-12T23:23:17.126918Z","shell.execute_reply":"2021-08-12T23:23:17.130529Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"history = model.fit(train_imgs,  steps_per_epoch=1000, epochs=100, verbose=1, validation_data=valid_imgs, \n                    class_weight=class_weight, callbacks=[checkpoint_cb, earlystop_cb])","metadata":{"execution":{"iopub.status.busy":"2021-08-13T01:22:15.207141Z","iopub.execute_input":"2021-08-13T01:22:15.207479Z","iopub.status.idle":"2021-08-13T03:14:32.030514Z","shell.execute_reply.started":"2021-08-13T01:22:15.207432Z","shell.execute_reply":"2021-08-13T03:14:32.029106Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stdout","text":"Epoch 1/100\n1000/1000 [==============================] - 564s 564ms/step - loss: 0.7599 - f1_score: 0.7299 - val_loss: 0.6973 - val_f1_score: 0.7324\nEpoch 2/100\n1000/1000 [==============================] - 560s 561ms/step - loss: 0.7544 - f1_score: 0.7324 - val_loss: 0.6826 - val_f1_score: 0.7257\nEpoch 3/100\n1000/1000 [==============================] - 560s 560ms/step - loss: 0.7640 - f1_score: 0.7301 - val_loss: 0.7895 - val_f1_score: 0.6768\nEpoch 4/100\n1000/1000 [==============================] - 559s 559ms/step - loss: 0.7515 - f1_score: 0.7309 - val_loss: 0.6657 - val_f1_score: 0.7429\nEpoch 5/100\n1000/1000 [==============================] - 560s 560ms/step - loss: 0.7506 - f1_score: 0.7303 - val_loss: 0.7737 - val_f1_score: 0.6852\nEpoch 6/100\n1000/1000 [==============================] - 571s 571ms/step - loss: 0.7461 - f1_score: 0.7352 - val_loss: 0.6883 - val_f1_score: 0.7360\nEpoch 7/100\n1000/1000 [==============================] - 569s 569ms/step - loss: 0.7373 - f1_score: 0.7362 - val_loss: 0.5947 - val_f1_score: 0.7849\nEpoch 8/100\n1000/1000 [==============================] - 560s 560ms/step - loss: 0.7424 - f1_score: 0.7380 - val_loss: 0.6459 - val_f1_score: 0.7441\nEpoch 9/100\n1000/1000 [==============================] - 567s 567ms/step - loss: 0.7409 - f1_score: 0.7383 - val_loss: 0.6810 - val_f1_score: 0.7319\nEpoch 10/100\n1000/1000 [==============================] - 552s 552ms/step - loss: 0.7356 - f1_score: 0.7386 - val_loss: 0.6472 - val_f1_score: 0.7595\nEpoch 11/100\n1000/1000 [==============================] - 566s 566ms/step - loss: 0.7371 - f1_score: 0.7377 - val_loss: 0.6670 - val_f1_score: 0.7405\nEpoch 12/100\n1000/1000 [==============================] - 546s 546ms/step - loss: 0.7389 - f1_score: 0.7364 - val_loss: 0.7199 - val_f1_score: 0.7103\n","output_type":"stream"}]},{"cell_type":"code","source":"test_image_datagen = ImageDataGenerator( rescale = 1./255.)\n\ntest_imgs = test_image_datagen.flow_from_dataframe(test_df, directory=None, x_col='FILENAME', y_col=cols, validate_filenames=True,\n                                        class_mode=\"raw\", target_size=(224,224), batch_size=32)","metadata":{"execution":{"iopub.status.busy":"2021-08-13T03:14:32.035392Z","iopub.execute_input":"2021-08-13T03:14:32.037261Z","iopub.status.idle":"2021-08-13T03:14:33.453480Z","shell.execute_reply.started":"2021-08-13T03:14:32.037218Z","shell.execute_reply":"2021-08-13T03:14:33.452645Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stdout","text":"Found 968 validated image filenames.\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/keras_preprocessing/image/dataframe_iterator.py:282: UserWarning: Found 4 invalid image filename(s) in x_col=\"FILENAME\". These filename(s) will be ignored.\n  .format(n_invalid, x_col)\n","output_type":"stream"}]},{"cell_type":"code","source":"model.load_weights(\"oct_xception50per.h5\")\nmodel.evaluate(test_imgs)","metadata":{"execution":{"iopub.status.busy":"2021-08-13T03:14:33.455292Z","iopub.execute_input":"2021-08-13T03:14:33.455869Z","iopub.status.idle":"2021-08-13T03:14:41.929771Z","shell.execute_reply.started":"2021-08-13T03:14:33.455805Z","shell.execute_reply":"2021-08-13T03:14:41.929018Z"},"trusted":true},"execution_count":41,"outputs":[{"name":"stdout","text":"31/31 [==============================] - 8s 259ms/step - loss: 0.4134 - f1_score: 0.8378\n","output_type":"stream"},{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"[0.4133928716182709, 0.8378099203109741]"},"metadata":{}}]}]}